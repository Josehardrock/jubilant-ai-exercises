{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Ejercicio 3\n","# •\tDefine una clase de modelo simple en PyTorch con una capa lineal y una función de activación ReLU.\n","\n","import torch\n","import torch.nn as nn\n","\n","#ClassName\n","class SimpleModel(nn.Module):\n","    #Constructor\n","    def __init__(self, input_size, output_size):\n","        #Initialize base class or super class as called in python\n","        super(SimpleModel, self).__init__()\n","\n","        #Define the layers\n","        self.linear = nn.Linear(input_size, output_size)\n","\n","        #Define the activation function ReLU (Rectified Linear Unit)\n","        self.relu = nn.ReLU()\n"]}],"metadata":{"kernelspec":{"display_name":"session4","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":2}
